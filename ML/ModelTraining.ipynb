{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e900754-a2b3-4fda-b0f3-fdf01370e777",
   "metadata": {},
   "source": [
    "# 1. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "929c776f-c733-4cfc-99ae-995d96617289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc227484-ce18-4242-a7ee-53781af07bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1bf82e9-9295-4e16-b04e-7edfdf9a91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('models'),\n",
    "    'ANNOTATION_PATH': os.path.join('workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('protoc')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5ed0f5-f79e-4d6e-a2e4-72d467e88dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('workspace', 'models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a504675-498a-41b1-b835-fcaffb889db3",
   "metadata": {},
   "source": [
    "Loop to automate creating all the folders/paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19489c3b-f995-480a-8c5a-8059c540f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "            !mkdir -p {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36870df-5ac0-4180-93ab-bdd65ba56fba",
   "metadata": {},
   "source": [
    "# 2. TensorFlow Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753fb63-865d-4a1c-ad4e-d02257dbdffb",
   "metadata": {},
   "source": [
    "### Clone TensorFlow Garden into models folder to use the TensorFlow Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de7471e-a0b9-4131-be85-83222aa5c953",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 61634, done.\u001b[K\n",
      "remote: Total 61634 (delta 0), reused 0 (delta 0), pack-reused 61634\u001b[K\n",
      "Receiving objects: 100% (61634/61634), 574.24 MiB | 5.29 MiB/s, done.\n",
      "Resolving deltas: 100% (42913/42913), done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b5372-5418-4423-a59d-d639db698224",
   "metadata": {},
   "source": [
    "### Install Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4776e3db-afce-43bd-84a4-eb509ab1ad4c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/aideen/WeaponDetection/ML/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Collecting avro-python3\n",
      "  Using cached avro-python3-1.10.2.tar.gz (38 kB)\n",
      "Collecting apache-beam\n",
      "  Using cached apache_beam-2.32.0-cp38-cp38-macosx_10_9_x86_64.whl (4.2 MB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-8.3.2-cp38-cp38-macosx_10_10_x86_64.whl (3.0 MB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-4.6.3-cp38-cp38-macosx_10_9_x86_64.whl (4.6 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.4.3-cp38-cp38-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "Collecting Cython\n",
      "  Using cached Cython-0.29.24-cp38-cp38-macosx_10_9_x86_64.whl (1.9 MB)\n",
      "Collecting contextlib2\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tf-slim\n",
      "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Requirement already satisfied: six in /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages (from object-detection==0.1) (1.16.0)\n",
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.2.tar.gz (23 kB)\n",
      "Collecting lvis\n",
      "  Using cached lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.7.1-cp38-cp38-macosx_10_9_x86_64.whl (32.6 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl (11.4 MB)\n",
      "Collecting tf-models-official>=2.5.1\n",
      "  Using cached tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
      "Collecting tensorflow>=2.5.0\n",
      "  Using cached tensorflow-2.6.0-cp38-cp38-macosx_10_11_x86_64.whl (199.0 MB)\n",
      "Collecting numpy>=1.15.4\n",
      "  Using cached numpy-1.21.2-cp38-cp38-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-5.4.1-cp38-cp38-macosx_10_9_x86_64.whl (253 kB)\n",
      "Collecting oauth2client\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Collecting tensorflow-hub>=0.6.0\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Using cached tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n",
      "Collecting gin-config\n",
      "  Using cached gin_config-0.4.0-py2.py3-none-any.whl (46 kB)\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "Collecting tensorflow-addons\n",
      "  Using cached tensorflow_addons-0.14.0-cp38-cp38-macosx_10_13_x86_64.whl (575 kB)\n",
      "Collecting tensorflow-datasets\n",
      "  Using cached tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Using cached py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp38-cp38-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "Collecting tensorflow-text>=2.5.0\n",
      "  Using cached tensorflow_text-2.6.0-cp38-cp38-macosx_10_9_x86_64.whl (3.6 MB)\n",
      "Collecting psutil>=5.4.3\n",
      "  Using cached psutil-5.8.0-cp38-cp38-macosx_10_9_x86_64.whl (236 kB)\n",
      "Collecting kaggle>=1.3.9\n",
      "  Using cached kaggle-1.5.12.tar.gz (58 kB)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.5.3.56-cp38-cp38-macosx_10_15_x86_64.whl (42.6 MB)\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Using cached google_api_python_client-2.19.1-py2.py3-none-any.whl (7.4 MB)\n",
      "Collecting google-auth<3.0.0dev,>=1.16.0\n",
      "  Using cached google_auth-2.0.2-py2.py3-none-any.whl (152 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Using cached httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "Collecting google-auth-httplib2>=0.1.0\n",
      "  Using cached google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=1.21.0\n",
      "  Using cached google_api_core-2.0.1-py2.py3-none-any.whl (92 kB)\n",
      "Collecting uritemplate<4dev,>=3.0.0\n",
      "  Using cached uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting requests<3.0.0dev,>=2.18.0\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Using cached googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (49.2.1)\n",
      "Collecting protobuf>=3.12.0\n",
      "  Using cached protobuf-3.17.3-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyparsing<3,>=2.4.2\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting certifi\n",
      "  Using cached certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "Requirement already satisfied: python-dateutil in /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n",
      "Collecting python-slugify\n",
      "  Using cached python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Collecting urllib3\n",
      "  Using cached urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting pytz>=2017.3\n",
      "  Using cached pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.2-py3-none-any.whl (59 kB)\n",
      "Collecting six\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting keras~=2.6\n",
      "  Using cached keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting numpy>=1.15.4\n",
      "  Using cached numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting clang~=5.0\n",
      "  Using cached clang-5.0-py3-none-any.whl\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Using cached grpcio-1.39.0-cp38-cp38-macosx_10_10_x86_64.whl (3.9 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Using cached tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Using cached tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting google-auth<3.0.0dev,>=1.16.0\n",
      "  Using cached google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Using cached dm_tree-0.1.6-cp38-cp38-macosx_10_14_x86_64.whl (95 kB)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Using cached crcmod-1.7.tar.gz (89 kB)\n",
      "Collecting orjson<4.0\n",
      "  Using cached orjson-3.6.3-cp38-cp38-macosx_10_9_x86_64.macosx_11_0_arm64.macosx_10_9_universal2.whl (434 kB)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Using cached pymongo-3.12.0-cp38-cp38-macosx_10_9_x86_64.whl (394 kB)\n",
      "Collecting future<1.0.0,>=0.18.2\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "  Using cached dill-0.3.1.1.tar.gz (151 kB)\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Using cached hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Collecting pyarrow<5.0.0,>=0.15.1\n",
      "  Using cached pyarrow-4.0.1-cp38-cp38-macosx_10_13_x86_64.whl (15.7 MB)\n",
      "Collecting avro-python3\n",
      "  Using cached avro-python3-1.9.2.1.tar.gz (37 kB)\n",
      "Collecting fastavro<2,>=0.21.4\n",
      "  Using cached fastavro-1.4.4-cp38-cp38-macosx_10_14_x86_64.whl (483 kB)\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting docopt\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Using cached opencv_python-4.5.3.56-cp38-cp38-macosx_10_15_x86_64.whl (42.6 MB)\n",
      "Collecting cycler>=0.10.0\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.1.0\n",
      "  Using cached kiwisolver-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl (61 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting regex\n",
      "  Using cached regex-2021.8.28-cp38-cp38-macosx_10_9_x86_64.whl (285 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Using cached scikit_learn-0.24.2-cp38-cp38-macosx_10_13_x86_64.whl (7.2 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting typeguard>=2.7\n",
      "  Using cached typeguard-2.12.1-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-5.2.2-py3-none-any.whl (27 kB)\n",
      "Collecting tensorflow-metadata\n",
      "  Using cached tensorflow_metadata-1.2.0-py3-none-any.whl (48 kB)\n",
      "Collecting promise\n",
      "  Using cached promise-2.3.tar.gz (19 kB)\n",
      "Collecting attrs>=18.1.0\n",
      "  Using cached attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting zipp>=3.1.0\n",
      "  Using cached zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Using legacy 'setup.py install' for object-detection, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for kaggle, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for py-cpuinfo, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for wrapt, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for avro-python3, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for crcmod, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for dill, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for future, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for docopt, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pycocotools, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for seqeval, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for promise, since package 'wheel' is not installed.\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, pyparsing, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, zipp, wrapt, typing-extensions, threadpoolctl, text-unidecode, termcolor, tensorflow-estimator, tensorboard, scipy, pillow, opt-einsum, kiwisolver, keras-preprocessing, keras, joblib, httplib2, h5py, googleapis-common-protos, google-pasta, gast, flatbuffers, cycler, clang, astunparse, uritemplate, typeguard, tqdm, tensorflow-metadata, tensorflow-hub, tensorflow, tabulate, scikit-learn, regex, pytz, python-slugify, promise, portalocker, matplotlib, importlib-resources, google-auth-httplib2, google-api-core, future, docopt, dm-tree, dill, Cython, colorama, attrs, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-datasets, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, pydot, pycocotools, pyarrow, py-cpuinfo, psutil, pandas, orjson, opencv-python-headless, opencv-python, oauth2client, kaggle, hdfs, google-api-python-client, gin-config, fastavro, crcmod, avro-python3, tf-models-official, lxml, lvis, contextlib2, apache-beam, object-detection\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "    Running setup.py install for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for promise ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for future ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for docopt ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for dill ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for seqeval ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for pycocotools ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for py-cpuinfo ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for kaggle ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for crcmod ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for avro-python3 ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for object-detection ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Cython-0.29.24 absl-py-0.12.0 apache-beam-2.32.0 astunparse-1.6.3 attrs-21.2.0 avro-python3-1.9.2.1 cachetools-4.2.2 certifi-2021.5.30 charset-normalizer-2.0.4 clang-5.0 colorama-0.4.4 contextlib2-21.6.0 crcmod-1.7 cycler-0.10.0 dill-0.3.1.1 dm-tree-0.1.6 docopt-0.6.2 fastavro-1.4.4 flatbuffers-1.12 future-0.18.2 gast-0.4.0 gin-config-0.4.0 google-api-core-2.0.1 google-api-python-client-2.19.1 google-auth-1.35.0 google-auth-httplib2-0.1.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.53.0 grpcio-1.39.0 h5py-3.1.0 hdfs-2.6.0 httplib2-0.19.1 idna-3.2 importlib-resources-5.2.2 joblib-1.0.1 kaggle-1.5.12 keras-2.6.0 keras-preprocessing-1.1.2 kiwisolver-1.3.2 lvis-0.5.3 lxml-4.6.3 markdown-3.3.4 matplotlib-3.4.3 numpy-1.19.5 oauth2client-4.1.3 oauthlib-3.1.1 object-detection-0.1 opencv-python-4.5.3.56 opencv-python-headless-4.5.3.56 opt-einsum-3.3.0 orjson-3.6.3 pandas-1.3.2 pillow-8.3.2 portalocker-2.3.2 promise-2.3 protobuf-3.17.3 psutil-5.8.0 py-cpuinfo-8.0.0 pyarrow-4.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycocotools-2.0.2 pydot-1.4.2 pymongo-3.12.0 pyparsing-2.4.7 python-slugify-5.0.2 pytz-2021.1 pyyaml-5.4.1 regex-2021.8.28 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 sacrebleu-2.0.0 scikit-learn-0.24.2 scipy-1.7.1 sentencepiece-0.1.96 seqeval-1.2.2 six-1.15.0 tabulate-0.8.9 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-addons-0.14.0 tensorflow-datasets-4.4.0 tensorflow-estimator-2.6.0 tensorflow-hub-0.12.0 tensorflow-metadata-1.2.0 tensorflow-model-optimization-0.6.0 tensorflow-text-2.6.0 termcolor-1.1.0 text-unidecode-1.3 tf-models-official-2.6.0 tf-slim-1.1.0 threadpoolctl-2.2.0 tqdm-4.62.2 typeguard-2.12.1 typing-extensions-3.7.4.3 uritemplate-3.0.1 urllib3-1.26.6 werkzeug-2.0.1 wheel-0.37.0 wrapt-1.12.1 zipp-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!cd models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f585dd8-9f68-411c-9b63-a60e2488c3a4",
   "metadata": {},
   "source": [
    "# 3. Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503d3e1a-a957-481c-9c88-45798d66aabe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.8.8: /Users/aideen/WeaponDetection/weap-detect/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2021-09-06 11:35:44.762235: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/object_detection/builders/model_builder.py:1091: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0906 11:35:45.053761 4689042880 model_builder.py:1091] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.55s\n",
      "I0906 11:35:45.312074 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.55s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.7s\n",
      "I0906 11:35:46.011745 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.7s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n",
      "I0906 11:35:46.345771 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
      "I0906 11:35:46.594233 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "W0906 11:35:46.596743 4689042880 mobilenet_v2.py:297] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.81s\n",
      "I0906 11:35:48.401887 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.81s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0906 11:35:48.402925 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0906 11:35:48.423087 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0906 11:35:48.437029 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I0906 11:35:48.454319 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.2s\n",
      "I0906 11:35:48.652294 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.2s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
      "I0906 11:35:48.763888 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "I0906 11:35:48.856579 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "I0906 11:35:48.950718 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
      "I0906 11:35:49.049619 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "I0906 11:35:49.079218 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0906 11:35:49.264958 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0906 11:35:49.265112 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0906 11:35:49.265178 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I0906 11:35:49.267556 4689042880 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0906 11:35:49.283887 4689042880 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0906 11:35:49.284095 4689042880 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0906 11:35:49.345408 4689042880 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0906 11:35:49.345587 4689042880 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0906 11:35:49.490637 4689042880 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0906 11:35:49.490773 4689042880 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0906 11:35:49.634619 4689042880 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0906 11:35:49.634738 4689042880 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0906 11:35:49.837130 4689042880 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0906 11:35:49.837266 4689042880 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0906 11:35:50.052381 4689042880 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0906 11:35:50.052522 4689042880 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0906 11:35:50.360464 4689042880 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0906 11:35:50.360589 4689042880 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0906 11:35:50.438786 4689042880 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0906 11:35:50.480261 4689042880 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0906 11:35:50.541939 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0906 11:35:50.542093 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I0906 11:35:50.542162 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 4\n",
      "I0906 11:35:50.544071 4689042880 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0906 11:35:50.560079 4689042880 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0906 11:35:50.560220 4689042880 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0906 11:35:50.689829 4689042880 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0906 11:35:50.689988 4689042880 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0906 11:35:50.898750 4689042880 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0906 11:35:50.898927 4689042880 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0906 11:35:51.143636 4689042880 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0906 11:35:51.143793 4689042880 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0906 11:35:51.473776 4689042880 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0906 11:35:51.473893 4689042880 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0906 11:35:51.841221 4689042880 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0906 11:35:51.841352 4689042880 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0906 11:35:52.212698 4689042880 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0906 11:35:52.212862 4689042880 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0906 11:35:52.404464 4689042880 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0906 11:35:52.444730 4689042880 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0906 11:35:52.509799 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0906 11:35:52.509932 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0906 11:35:52.509986 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 5\n",
      "I0906 11:35:52.511550 4689042880 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0906 11:35:52.528537 4689042880 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0906 11:35:52.528666 4689042880 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0906 11:35:52.650417 4689042880 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0906 11:35:52.650575 4689042880 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0906 11:35:52.877909 4689042880 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0906 11:35:52.878039 4689042880 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0906 11:35:53.146819 4689042880 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0906 11:35:53.146952 4689042880 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0906 11:35:53.451470 4689042880 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0906 11:35:53.451611 4689042880 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0906 11:35:53.766643 4689042880 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0906 11:35:53.766836 4689042880 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0906 11:35:54.140012 4689042880 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0906 11:35:54.140141 4689042880 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0906 11:35:54.336302 4689042880 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0906 11:35:54.388440 4689042880 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0906 11:35:54.465573 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0906 11:35:54.465722 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I0906 11:35:54.465791 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 6\n",
      "I0906 11:35:54.467637 4689042880 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0906 11:35:54.482597 4689042880 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0906 11:35:54.482745 4689042880 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0906 11:35:54.602164 4689042880 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0906 11:35:54.602313 4689042880 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0906 11:35:54.844233 4689042880 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0906 11:35:54.844422 4689042880 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0906 11:35:55.052632 4689042880 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0906 11:35:55.052772 4689042880 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0906 11:35:55.485352 4689042880 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0906 11:35:55.485506 4689042880 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0906 11:35:56.158938 4689042880 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0906 11:35:56.159085 4689042880 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0906 11:35:56.837796 4689042880 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0906 11:35:56.837982 4689042880 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0906 11:35:57.106487 4689042880 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0906 11:35:57.164333 4689042880 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0906 11:35:57.284230 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0906 11:35:57.284475 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I0906 11:35:57.284569 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0906 11:35:57.287719 4689042880 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0906 11:35:57.315093 4689042880 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0906 11:35:57.315290 4689042880 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0906 11:35:57.497194 4689042880 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0906 11:35:57.497341 4689042880 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0906 11:35:57.893512 4689042880 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0906 11:35:57.893669 4689042880 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0906 11:35:58.218518 4689042880 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0906 11:35:58.218667 4689042880 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0906 11:35:58.798125 4689042880 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0906 11:35:58.798276 4689042880 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0906 11:35:59.318089 4689042880 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0906 11:35:59.318234 4689042880 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0906 11:36:00.042428 4689042880 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0906 11:36:00.042582 4689042880 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0906 11:36:00.246905 4689042880 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0906 11:36:00.297852 4689042880 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0906 11:36:00.400105 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0906 11:36:00.400257 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I0906 11:36:00.400335 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0906 11:36:00.402267 4689042880 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0906 11:36:00.417829 4689042880 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0906 11:36:00.417977 4689042880 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0906 11:36:00.602178 4689042880 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0906 11:36:00.602342 4689042880 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0906 11:36:00.942316 4689042880 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0906 11:36:00.942469 4689042880 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0906 11:36:01.488134 4689042880 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0906 11:36:01.488279 4689042880 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0906 11:36:02.039232 4689042880 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0906 11:36:02.039368 4689042880 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0906 11:36:02.554329 4689042880 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0906 11:36:02.554468 4689042880 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0906 11:36:03.325911 4689042880 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0906 11:36:03.326053 4689042880 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0906 11:36:03.670053 4689042880 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0906 11:36:03.727380 4689042880 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0906 11:36:03.838248 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0906 11:36:03.838391 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0906 11:36:03.838453 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0906 11:36:03.840183 4689042880 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0906 11:36:03.855308 4689042880 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0906 11:36:03.855463 4689042880 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0906 11:36:04.050863 4689042880 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0906 11:36:04.051022 4689042880 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0906 11:36:04.482868 4689042880 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0906 11:36:04.483014 4689042880 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0906 11:36:04.889815 4689042880 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0906 11:36:04.889954 4689042880 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0906 11:36:05.511317 4689042880 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0906 11:36:05.511471 4689042880 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0906 11:36:06.343369 4689042880 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0906 11:36:06.343535 4689042880 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0906 11:36:07.391301 4689042880 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0906 11:36:07.391482 4689042880 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0906 11:36:07.773973 4689042880 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0906 11:36:07.837545 4689042880 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0906 11:36:07.968030 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0906 11:36:07.968172 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0906 11:36:07.968232 4689042880 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0906 11:36:07.969933 4689042880 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0906 11:36:07.985697 4689042880 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0906 11:36:07.985835 4689042880 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0906 11:36:08.226238 4689042880 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0906 11:36:08.226383 4689042880 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0906 11:36:08.746543 4689042880 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0906 11:36:08.746671 4689042880 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0906 11:36:09.242516 4689042880 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0906 11:36:09.242676 4689042880 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0906 11:36:10.016937 4689042880 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0906 11:36:10.017107 4689042880 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0906 11:36:10.816755 4689042880 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0906 11:36:10.816901 4689042880 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0906 11:36:12.281901 4689042880 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0906 11:36:12.282104 4689042880 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0906 11:36:12.869193 4689042880 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0906 11:36:12.949669 4689042880 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.03s\n",
      "I0906 11:36:13.113389 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0906 11:36:13.125017 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0906 11:36:13.126829 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0906 11:36:13.127264 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0906 11:36:13.128826 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0906 11:36:13.130266 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0906 11:36:13.130625 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0906 11:36:13.131660 4689042880 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 28.375s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcd087-06a7-4a80-a7aa-c462f6ae7794",
   "metadata": {},
   "source": [
    "# 4. Download Pre-Trained Model From TensorFlow 2 Detection Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f23d1b83-ac5d-4e7d-a778-ba49c6093fc2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-06 11:48:41--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.64.80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.64.80|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20515344 (20M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  5.52MB/s    in 4.7s    \n",
      "\n",
      "2021-09-06 11:48:46 (4.19 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
      "\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!wget {PRETRAINED_MODEL_URL}\n",
    "!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab2296-0e41-43d5-b569-8db36855ef0c",
   "metadata": {},
   "source": [
    "# 5. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21c0992b-83d6-4b9f-a4f3-23851b4db8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'Gun', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c5fed-46c6-4c3d-b79c-36f371abac95",
   "metadata": {},
   "source": [
    "# 6. Create TFRecords\n",
    "\n",
    "- TFRecords are a binary format for storing data. Using TFRecords speeds up training for the custom object detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97327d55-2d48-42a6-8bcf-11584a566cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67491fc2-e932-4b4b-b543-5a2a69dfdb5b",
   "metadata": {},
   "source": [
    "# 7. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf0e8df4-5f00-480d-9021-54827fce4003",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e8be4-8a57-4a1e-931e-651dc4dec69e",
   "metadata": {},
   "source": [
    "# 8. Update Config for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0eacf02-5411-475c-b74e-10f5142c690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5fc50d1-1110-4e82-96ca-4f3ddead0fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7d4004-068a-46b9-becd-60ca8e784537",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60c35bae-fc27-4d2b-9dbf-eb18ae3e5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = 1\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff6fdfa4-16f8-434f-8d47-0ef5a7712b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126172c-58ec-415f-95b6-1f30326bd518",
   "metadata": {},
   "source": [
    "# 9. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0672b585-1766-4fbc-90bd-930d84944b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "303f852f-bb6a-4077-bf68-2a6ab9a8fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5de3174e-d6f8-44c4-bfa3-0f8f67025379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python models/research/object_detection/model_main_tf2.py --model_dir=workspace/models/my_ssd_mobnet --pipeline_config_path=workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1ebe77a-d8ad-49a4-a236-bc24608a8a65",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-06 12:10:31.996695: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0906 12:10:31.997338 4432461248 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0906 12:10:32.016903 4432461248 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
      "I0906 12:10:32.024221 4432461248 config_util.py:552] Maybe overwriting train_steps: 2000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0906 12:10:32.024477 4432461248 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0906 12:10:32.068181 4432461248 deprecation.py:339] From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['workspace/annotations/train.record']\n",
      "I0906 12:10:32.071156 4432461248 dataset_builder.py:163] Reading unweighted datasets: ['workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['workspace/annotations/train.record']\n",
      "I0906 12:10:32.071324 4432461248 dataset_builder.py:80] Reading record datasets for input file: ['workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0906 12:10:32.071379 4432461248 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0906 12:10:32.071420 4432461248 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0906 12:10:32.074604 4432461248 deprecation.py:339] From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0906 12:10:32.102331 4432461248 deprecation.py:339] From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0906 12:10:37.998253 4432461248 deprecation.py:339] From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0906 12:10:40.742071 4432461248 deprecation.py:339] From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0906 12:10:42.229018 4432461248 deprecation.py:339] From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-09-06 12:10:44.279883: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-06 12:10:44.562797: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "/Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0906 12:11:03.378043 123145516781568 deprecation.py:542] From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 100 per-step time 1.697s\n",
      "I0906 12:13:52.786525 4432461248 model_lib_v2.py:698] Step 100 per-step time 1.697s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3088614,\n",
      " 'Loss/localization_loss': 0.2837133,\n",
      " 'Loss/regularization_loss': 0.15441145,\n",
      " 'Loss/total_loss': 0.74698615,\n",
      " 'learning_rate': 0.0319994}\n",
      "I0906 12:13:52.787015 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.3088614,\n",
      " 'Loss/localization_loss': 0.2837133,\n",
      " 'Loss/regularization_loss': 0.15441145,\n",
      " 'Loss/total_loss': 0.74698615,\n",
      " 'learning_rate': 0.0319994}\n",
      "INFO:tensorflow:Step 200 per-step time 1.431s\n",
      "I0906 12:16:15.932106 4432461248 model_lib_v2.py:698] Step 200 per-step time 1.431s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16928439,\n",
      " 'Loss/localization_loss': 0.119525924,\n",
      " 'Loss/regularization_loss': 0.15437935,\n",
      " 'Loss/total_loss': 0.44318968,\n",
      " 'learning_rate': 0.0373328}\n",
      "I0906 12:16:15.932489 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.16928439,\n",
      " 'Loss/localization_loss': 0.119525924,\n",
      " 'Loss/regularization_loss': 0.15437935,\n",
      " 'Loss/total_loss': 0.44318968,\n",
      " 'learning_rate': 0.0373328}\n",
      "INFO:tensorflow:Step 300 per-step time 1.344s\n",
      "I0906 12:18:30.353632 4432461248 model_lib_v2.py:698] Step 300 per-step time 1.344s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10327447,\n",
      " 'Loss/localization_loss': 0.11153154,\n",
      " 'Loss/regularization_loss': 0.15418261,\n",
      " 'Loss/total_loss': 0.36898863,\n",
      " 'learning_rate': 0.0426662}\n",
      "I0906 12:18:30.354009 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.10327447,\n",
      " 'Loss/localization_loss': 0.11153154,\n",
      " 'Loss/regularization_loss': 0.15418261,\n",
      " 'Loss/total_loss': 0.36898863,\n",
      " 'learning_rate': 0.0426662}\n",
      "INFO:tensorflow:Step 400 per-step time 1.309s\n",
      "I0906 12:20:41.232825 4432461248 model_lib_v2.py:698] Step 400 per-step time 1.309s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17507157,\n",
      " 'Loss/localization_loss': 0.082224876,\n",
      " 'Loss/regularization_loss': 0.15389799,\n",
      " 'Loss/total_loss': 0.4111944,\n",
      " 'learning_rate': 0.047999598}\n",
      "I0906 12:20:41.233168 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.17507157,\n",
      " 'Loss/localization_loss': 0.082224876,\n",
      " 'Loss/regularization_loss': 0.15389799,\n",
      " 'Loss/total_loss': 0.4111944,\n",
      " 'learning_rate': 0.047999598}\n",
      "INFO:tensorflow:Step 500 per-step time 1.294s\n",
      "I0906 12:22:50.614142 4432461248 model_lib_v2.py:698] Step 500 per-step time 1.294s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12543195,\n",
      " 'Loss/localization_loss': 0.10106717,\n",
      " 'Loss/regularization_loss': 0.15356188,\n",
      " 'Loss/total_loss': 0.38006103,\n",
      " 'learning_rate': 0.053333}\n",
      "I0906 12:22:50.614495 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.12543195,\n",
      " 'Loss/localization_loss': 0.10106717,\n",
      " 'Loss/regularization_loss': 0.15356188,\n",
      " 'Loss/total_loss': 0.38006103,\n",
      " 'learning_rate': 0.053333}\n",
      "INFO:tensorflow:Step 600 per-step time 1.300s\n",
      "I0906 12:25:00.614850 4432461248 model_lib_v2.py:698] Step 600 per-step time 1.300s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.101725034,\n",
      " 'Loss/localization_loss': 0.09545401,\n",
      " 'Loss/regularization_loss': 0.15314583,\n",
      " 'Loss/total_loss': 0.35032487,\n",
      " 'learning_rate': 0.0586664}\n",
      "I0906 12:25:00.615179 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.101725034,\n",
      " 'Loss/localization_loss': 0.09545401,\n",
      " 'Loss/regularization_loss': 0.15314583,\n",
      " 'Loss/total_loss': 0.35032487,\n",
      " 'learning_rate': 0.0586664}\n",
      "INFO:tensorflow:Step 700 per-step time 10.342s\n",
      "I0906 12:42:14.809725 4432461248 model_lib_v2.py:698] Step 700 per-step time 10.342s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07520002,\n",
      " 'Loss/localization_loss': 0.040209655,\n",
      " 'Loss/regularization_loss': 0.15268585,\n",
      " 'Loss/total_loss': 0.26809552,\n",
      " 'learning_rate': 0.0639998}\n",
      "I0906 12:42:14.809997 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.07520002,\n",
      " 'Loss/localization_loss': 0.040209655,\n",
      " 'Loss/regularization_loss': 0.15268585,\n",
      " 'Loss/total_loss': 0.26809552,\n",
      " 'learning_rate': 0.0639998}\n",
      "INFO:tensorflow:Step 800 per-step time 1.147s\n",
      "I0906 12:44:09.549747 4432461248 model_lib_v2.py:698] Step 800 per-step time 1.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.053496387,\n",
      " 'Loss/localization_loss': 0.036681797,\n",
      " 'Loss/regularization_loss': 0.1521194,\n",
      " 'Loss/total_loss': 0.24229759,\n",
      " 'learning_rate': 0.069333196}\n",
      "I0906 12:44:09.550122 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.053496387,\n",
      " 'Loss/localization_loss': 0.036681797,\n",
      " 'Loss/regularization_loss': 0.1521194,\n",
      " 'Loss/total_loss': 0.24229759,\n",
      " 'learning_rate': 0.069333196}\n",
      "INFO:tensorflow:Step 900 per-step time 1.369s\n",
      "I0906 12:46:26.439128 4432461248 model_lib_v2.py:698] Step 900 per-step time 1.369s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.101367585,\n",
      " 'Loss/localization_loss': 0.061750032,\n",
      " 'Loss/regularization_loss': 0.15157245,\n",
      " 'Loss/total_loss': 0.31469005,\n",
      " 'learning_rate': 0.074666604}\n",
      "I0906 12:46:26.439493 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.101367585,\n",
      " 'Loss/localization_loss': 0.061750032,\n",
      " 'Loss/regularization_loss': 0.15157245,\n",
      " 'Loss/total_loss': 0.31469005,\n",
      " 'learning_rate': 0.074666604}\n",
      "INFO:tensorflow:Step 1000 per-step time 1.414s\n",
      "I0906 12:48:47.795803 4432461248 model_lib_v2.py:698] Step 1000 per-step time 1.414s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.059112847,\n",
      " 'Loss/localization_loss': 0.029886581,\n",
      " 'Loss/regularization_loss': 0.15089582,\n",
      " 'Loss/total_loss': 0.23989525,\n",
      " 'learning_rate': 0.08}\n",
      "I0906 12:48:47.796160 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.059112847,\n",
      " 'Loss/localization_loss': 0.029886581,\n",
      " 'Loss/regularization_loss': 0.15089582,\n",
      " 'Loss/total_loss': 0.23989525,\n",
      " 'learning_rate': 0.08}\n",
      "INFO:tensorflow:Step 1100 per-step time 1.348s\n",
      "I0906 12:51:02.565133 4432461248 model_lib_v2.py:698] Step 1100 per-step time 1.348s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09752132,\n",
      " 'Loss/localization_loss': 0.042997554,\n",
      " 'Loss/regularization_loss': 0.1502346,\n",
      " 'Loss/total_loss': 0.29075348,\n",
      " 'learning_rate': 0.07999918}\n",
      "I0906 12:51:02.565493 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.09752132,\n",
      " 'Loss/localization_loss': 0.042997554,\n",
      " 'Loss/regularization_loss': 0.1502346,\n",
      " 'Loss/total_loss': 0.29075348,\n",
      " 'learning_rate': 0.07999918}\n",
      "INFO:tensorflow:Step 1200 per-step time 2.794s\n",
      "I0906 12:55:41.973937 4432461248 model_lib_v2.py:698] Step 1200 per-step time 2.794s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06355703,\n",
      " 'Loss/localization_loss': 0.033675212,\n",
      " 'Loss/regularization_loss': 0.14959192,\n",
      " 'Loss/total_loss': 0.24682416,\n",
      " 'learning_rate': 0.079996705}\n",
      "I0906 12:55:41.974271 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.06355703,\n",
      " 'Loss/localization_loss': 0.033675212,\n",
      " 'Loss/regularization_loss': 0.14959192,\n",
      " 'Loss/total_loss': 0.24682416,\n",
      " 'learning_rate': 0.079996705}\n",
      "INFO:tensorflow:Step 1300 per-step time 1.364s\n",
      "I0906 12:57:58.384253 4432461248 model_lib_v2.py:698] Step 1300 per-step time 1.364s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.061809245,\n",
      " 'Loss/localization_loss': 0.047116842,\n",
      " 'Loss/regularization_loss': 0.14884436,\n",
      " 'Loss/total_loss': 0.25777045,\n",
      " 'learning_rate': 0.0799926}\n",
      "I0906 12:57:58.384598 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.061809245,\n",
      " 'Loss/localization_loss': 0.047116842,\n",
      " 'Loss/regularization_loss': 0.14884436,\n",
      " 'Loss/total_loss': 0.25777045,\n",
      " 'learning_rate': 0.0799926}\n",
      "INFO:tensorflow:Step 1400 per-step time 1.576s\n",
      "I0906 13:00:35.980221 4432461248 model_lib_v2.py:698] Step 1400 per-step time 1.576s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.056826733,\n",
      " 'Loss/localization_loss': 0.017497778,\n",
      " 'Loss/regularization_loss': 0.14809218,\n",
      " 'Loss/total_loss': 0.2224167,\n",
      " 'learning_rate': 0.07998685}\n",
      "I0906 13:00:35.980605 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.056826733,\n",
      " 'Loss/localization_loss': 0.017497778,\n",
      " 'Loss/regularization_loss': 0.14809218,\n",
      " 'Loss/total_loss': 0.2224167,\n",
      " 'learning_rate': 0.07998685}\n",
      "INFO:tensorflow:Step 1500 per-step time 1.425s\n",
      "I0906 13:02:58.491760 4432461248 model_lib_v2.py:698] Step 1500 per-step time 1.425s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.04074314,\n",
      " 'Loss/localization_loss': 0.016199652,\n",
      " 'Loss/regularization_loss': 0.14734235,\n",
      " 'Loss/total_loss': 0.20428514,\n",
      " 'learning_rate': 0.07997945}\n",
      "I0906 13:02:58.492105 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.04074314,\n",
      " 'Loss/localization_loss': 0.016199652,\n",
      " 'Loss/regularization_loss': 0.14734235,\n",
      " 'Loss/total_loss': 0.20428514,\n",
      " 'learning_rate': 0.07997945}\n",
      "INFO:tensorflow:Step 1600 per-step time 1.377s\n",
      "I0906 13:05:16.209447 4432461248 model_lib_v2.py:698] Step 1600 per-step time 1.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06409673,\n",
      " 'Loss/localization_loss': 0.013123714,\n",
      " 'Loss/regularization_loss': 0.1465912,\n",
      " 'Loss/total_loss': 0.22381166,\n",
      " 'learning_rate': 0.079970405}\n",
      "I0906 13:05:16.210053 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.06409673,\n",
      " 'Loss/localization_loss': 0.013123714,\n",
      " 'Loss/regularization_loss': 0.1465912,\n",
      " 'Loss/total_loss': 0.22381166,\n",
      " 'learning_rate': 0.079970405}\n",
      "INFO:tensorflow:Step 1700 per-step time 1.323s\n",
      "I0906 13:07:28.474504 4432461248 model_lib_v2.py:698] Step 1700 per-step time 1.323s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0910506,\n",
      " 'Loss/localization_loss': 0.023084326,\n",
      " 'Loss/regularization_loss': 0.1458326,\n",
      " 'Loss/total_loss': 0.2599675,\n",
      " 'learning_rate': 0.07995972}\n",
      "I0906 13:07:28.474831 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.0910506,\n",
      " 'Loss/localization_loss': 0.023084326,\n",
      " 'Loss/regularization_loss': 0.1458326,\n",
      " 'Loss/total_loss': 0.2599675,\n",
      " 'learning_rate': 0.07995972}\n",
      "INFO:tensorflow:Step 1800 per-step time 1.320s\n",
      "I0906 13:09:40.482479 4432461248 model_lib_v2.py:698] Step 1800 per-step time 1.320s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.05084603,\n",
      " 'Loss/localization_loss': 0.021308731,\n",
      " 'Loss/regularization_loss': 0.14507635,\n",
      " 'Loss/total_loss': 0.21723111,\n",
      " 'learning_rate': 0.0799474}\n",
      "I0906 13:09:40.482831 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.05084603,\n",
      " 'Loss/localization_loss': 0.021308731,\n",
      " 'Loss/regularization_loss': 0.14507635,\n",
      " 'Loss/total_loss': 0.21723111,\n",
      " 'learning_rate': 0.0799474}\n",
      "INFO:tensorflow:Step 1900 per-step time 1.350s\n",
      "I0906 13:11:55.453599 4432461248 model_lib_v2.py:698] Step 1900 per-step time 1.350s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.033778846,\n",
      " 'Loss/localization_loss': 0.014403352,\n",
      " 'Loss/regularization_loss': 0.14430599,\n",
      " 'Loss/total_loss': 0.1924882,\n",
      " 'learning_rate': 0.07993342}\n",
      "I0906 13:11:55.453973 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.033778846,\n",
      " 'Loss/localization_loss': 0.014403352,\n",
      " 'Loss/regularization_loss': 0.14430599,\n",
      " 'Loss/total_loss': 0.1924882,\n",
      " 'learning_rate': 0.07993342}\n",
      "INFO:tensorflow:Step 2000 per-step time 1.325s\n",
      "I0906 13:14:07.946773 4432461248 model_lib_v2.py:698] Step 2000 per-step time 1.325s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.053322062,\n",
      " 'Loss/localization_loss': 0.020164171,\n",
      " 'Loss/regularization_loss': 0.14353797,\n",
      " 'Loss/total_loss': 0.2170242,\n",
      " 'learning_rate': 0.07991781}\n",
      "I0906 13:14:07.947120 4432461248 model_lib_v2.py:701] {'Loss/classification_loss': 0.053322062,\n",
      " 'Loss/localization_loss': 0.020164171,\n",
      " 'Loss/regularization_loss': 0.14353797,\n",
      " 'Loss/total_loss': 0.2170242,\n",
      " 'learning_rate': 0.07991781}\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6fdc6-80bd-4bce-8263-8e5765ee556a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 10. Freeze/Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9961eff4-f6fd-4153-9916-26f34d59ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a17fa32d-96b0-412e-af6a-f5db85bba141",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1702222e-be2a-45f7-a0f9-8e13dd2a8e65",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-06 13:31:25.924834: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0906 13:31:26.116770 4565515712 deprecation.py:611] From /Users/aideen/WeaponDetection/weap-detect/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f992bec5640>, because it is not built.\n",
      "W0906 13:31:39.722276 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f992bec5640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f992bfab250>, because it is not built.\n",
      "W0906 13:31:40.139279 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f992bfab250>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f013c70>, because it is not built.\n",
      "W0906 13:31:40.139513 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f013c70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f013ca0>, because it is not built.\n",
      "W0906 13:31:40.139616 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f013ca0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f990f013f10>, because it is not built.\n",
      "W0906 13:31:40.139696 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f990f013f10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f013ee0>, because it is not built.\n",
      "W0906 13:31:40.139773 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f013ee0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f0136d0>, because it is not built.\n",
      "W0906 13:31:40.139847 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f0136d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f990f0057f0>, because it is not built.\n",
      "W0906 13:31:40.139919 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f990f0057f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f005280>, because it is not built.\n",
      "W0906 13:31:40.139991 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f005280>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f005400>, because it is not built.\n",
      "W0906 13:31:40.140064 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f005400>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f990f005d90>, because it is not built.\n",
      "W0906 13:31:40.140137 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f990f005d90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990e7223a0>, because it is not built.\n",
      "W0906 13:31:40.140210 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990e7223a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990e7220d0>, because it is not built.\n",
      "W0906 13:31:40.140285 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990e7220d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f992bfabac0>, because it is not built.\n",
      "W0906 13:31:40.140361 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f992bfabac0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe16670>, because it is not built.\n",
      "W0906 13:31:40.140434 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe16670>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f02ea90>, because it is not built.\n",
      "W0906 13:31:40.140506 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f02ea90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f02ea00>, because it is not built.\n",
      "W0906 13:31:40.140578 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f02ea00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990e71e790>, because it is not built.\n",
      "W0906 13:31:40.140651 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990e71e790>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990e71e040>, because it is not built.\n",
      "W0906 13:31:40.140724 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990e71e040>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990e71e670>, because it is not built.\n",
      "W0906 13:31:40.140796 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990e71e670>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990e71e580>, because it is not built.\n",
      "W0906 13:31:40.140866 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990e71e580>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f992bfabaf0>, because it is not built.\n",
      "W0906 13:31:40.140935 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f992bfabaf0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe31430>, because it is not built.\n",
      "W0906 13:31:40.141007 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe31430>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe29ee0>, because it is not built.\n",
      "W0906 13:31:40.141081 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe29ee0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe29f40>, because it is not built.\n",
      "W0906 13:31:40.141154 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe29f40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe3c490>, because it is not built.\n",
      "W0906 13:31:40.141226 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe3c490>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe3c2e0>, because it is not built.\n",
      "W0906 13:31:40.141299 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe3c2e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe3c520>, because it is not built.\n",
      "W0906 13:31:40.141370 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe3c520>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe3c790>, because it is not built.\n",
      "W0906 13:31:40.141441 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe3c790>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f992bfabb20>, because it is not built.\n",
      "W0906 13:31:40.141512 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f992bfabb20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990e73a9d0>, because it is not built.\n",
      "W0906 13:31:40.141667 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990e73a9d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe22af0>, because it is not built.\n",
      "W0906 13:31:40.141744 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe22af0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe22c40>, because it is not built.\n",
      "W0906 13:31:40.141818 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe22c40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe22f40>, because it is not built.\n",
      "W0906 13:31:40.141887 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe22f40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe22790>, because it is not built.\n",
      "W0906 13:31:40.141959 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe22790>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe22fd0>, because it is not built.\n",
      "W0906 13:31:40.142031 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe22fd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe22b80>, because it is not built.\n",
      "W0906 13:31:40.142112 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990fe22b80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe1dcd0>, because it is not built.\n",
      "W0906 13:31:40.142188 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990fe1dcd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f992c137a60>, because it is not built.\n",
      "W0906 13:31:40.142261 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f992c137a60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990dc24d30>, because it is not built.\n",
      "W0906 13:31:40.142342 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990dc24d30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990dc24370>, because it is not built.\n",
      "W0906 13:31:40.142416 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990dc24370>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f992c649ee0>, because it is not built.\n",
      "W0906 13:31:40.142488 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f992c649ee0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f06a7c0>, because it is not built.\n",
      "W0906 13:31:40.142560 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f06a7c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f06ad90>, because it is not built.\n",
      "W0906 13:31:40.142630 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f990f06ad90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f06a2e0>, because it is not built.\n",
      "W0906 13:31:40.142702 4565515712 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f990f06a2e0>, because it is not built.\n",
      "2021-09-06 13:31:48.811220: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0906 13:32:04.902442 4565515712 save.py:249] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: workspace/models/my_ssd_mobnet/export/saved_model/assets\n",
      "I0906 13:32:10.202353 4565515712 builder_impl.py:780] Assets written to: workspace/models/my_ssd_mobnet/export/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to workspace/models/my_ssd_mobnet/export/pipeline.config\n",
      "I0906 13:32:11.771944 4565515712 config_util.py:253] Writing pipeline config file to workspace/models/my_ssd_mobnet/export/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf33bb4-28de-407a-977e-1aa7d49319ed",
   "metadata": {},
   "source": [
    "# 10. Export to TFJS for use in Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f725f83-2bb0-4913-89ff-f4c71a339541",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "575301a5-9cac-4080-aee0-862d133a4e26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-06 13:33:41.993299: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-06 13:33:51.202934: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2021-09-06 13:33:51.203026: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2021-09-06 13:33:51.484771: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 3654 nodes (3244), 4879 edges (4462), time = 182.158ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 5.456ms.\n",
      "\n",
      "2021-09-06 13:33:55.273233: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  debug_stripper: Graph size after: 3380 nodes (0), 4687 edges (0), time = 11.468ms.\n",
      "  model_pruner: Graph size after: 2932 nodes (-448), 4239 edges (-448), time = 54.636ms.\n",
      "  constant_folding: Graph size after: 1404 nodes (-1528), 2471 edges (-1768), time = 227.337ms.\n",
      "  arithmetic_optimizer: Graph size after: 1420 nodes (16), 2481 edges (10), time = 46.827ms.\n",
      "  dependency_optimizer: Graph size after: 1325 nodes (-95), 1481 edges (-1000), time = 28.716ms.\n",
      "  model_pruner: Graph size after: 1325 nodes (0), 1481 edges (0), time = 16.046ms.\n",
      "  constant_folding: Graph size after: 1325 nodes (0), 1481 edges (0), time = 46.789ms.\n",
      "  arithmetic_optimizer: Graph size after: 1325 nodes (0), 1481 edges (0), time = 32.496ms.\n",
      "  dependency_optimizer: Graph size after: 1325 nodes (0), 1481 edges (0), time = 22.628ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 3.455ms.\n",
      "  model_pruner: Graph size after: 1325 nodes (0), 1481 edges (0), time = 12.02ms.\n",
      "  constant_folding: Graph size after: 1325 nodes (0), 1481 edges (0), time = 49.03ms.\n",
      "  arithmetic_optimizer: Graph size after: 1325 nodes (0), 1481 edges (0), time = 40.555ms.\n",
      "  dependency_optimizer: Graph size after: 1325 nodes (0), 1481 edges (0), time = 27.995ms.\n",
      "  model_pruner: Graph size after: 1325 nodes (0), 1481 edges (0), time = 17.239ms.\n",
      "  constant_folding: Graph size after: 1325 nodes (0), 1481 edges (0), time = 50.602ms.\n",
      "  arithmetic_optimizer: Graph size after: 1325 nodes (0), 1481 edges (0), time = 37.146ms.\n",
      "  dependency_optimizer: Graph size after: 1325 nodes (0), 1481 edges (0), time = 22.611ms.\n",
      "\n",
      "2021-09-06 13:34:04.898144: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  remapper: Graph size after: 1289 nodes (-112), 1141 edges (-112), time = 12.457ms.\n",
      "  constant_folding: Graph size after: 985 nodes (-304), 1141 edges (0), time = 84.494ms.\n",
      "  arithmetic_optimizer: Graph size after: 985 nodes (0), 1141 edges (0), time = 33.516ms.\n",
      "  dependency_optimizer: Graph size after: 985 nodes (0), 1141 edges (0), time = 22.205ms.\n",
      "  remapper: Graph size after: 985 nodes (0), 1141 edges (0), time = 14.228ms.\n",
      "  constant_folding: Graph size after: 985 nodes (0), 1141 edges (0), time = 48.677ms.\n",
      "  arithmetic_optimizer: Graph size after: 985 nodes (0), 1141 edges (0), time = 36.702ms.\n",
      "  dependency_optimizer: Graph size after: 985 nodes (0), 1141 edges (0), time = 22.529ms.\n",
      "\n",
      "Writing weight file workspace/models/my_ssd_mobnet/tfjsexport/model.json...\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weap-detect",
   "language": "python",
   "name": "weap-detect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
